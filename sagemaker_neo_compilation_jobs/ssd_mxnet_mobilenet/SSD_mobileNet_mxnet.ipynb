{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SSD model from S3, compile and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example to compile a pretrained MXNET SSD object detection model and deploy in sagemaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we will use the SSD mobilenet object detetion model. This model can be found in the gluoncv model zoo.\n",
    "\n",
    "We will use the SageMaker Python SDK to host this MXNET SSD model in SageMaker, and perform inference requests.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker import get_execution_role "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role() \n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'pretrained-mobilenet-mxnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker provides prebuilt Docker images that include deep learning framework libraries and other dependencies needed for training and inference. Check here for [Prebuilt Amazon SageMaker Docker Images for TensorFlow, MXNet, Chainer, and PyTorch](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = '301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-mxnet:1.4.1-cpu-py3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Preprocess and Postprocess Script\n",
    "\n",
    "The `entry_point.py` script provides the preprocess and postprocess methods that we need to correctly process the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat entry_point.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pretrained mobilenet model from S3\n",
    "\n",
    "After get the pretrained model from model zoo, we should compress the `model.json` and `model.params`  and upload the tarball to a S3 bucket for the SageMaker Python SDK to compile.\n",
    "\n",
    "You can read more about creating an `MXNetModel` object in the [SageMaker Python SDK API docs](https://sagemaker.readthedocs.io/en/stable/sagemaker.mxnet.html#mxnet-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "mobilenet_model = MXNetModel(\n",
    "    # insert model path below\n",
    "    model_data='s3:/your/path/to/model',\n",
    "    image=image_url,\n",
    "    entry_point='entry_point.py',\n",
    "    predictor_cls=RealTimePredictor,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    py_version='py3',\n",
    "    framework_version='1.4.1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile pretrained model\n",
    "\n",
    "Deploy using Neo API to optimize the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://{}/{}/test/output'.format(bucket, prefix)\n",
    "compiled_mobilenet = mobilenet_model.compile(target_instance_family='ml_c5', \n",
    "                                         input_shape={'data':[1,3,512,512]},\n",
    "                                         job_name='complied-pretrained-mobilenet-mxnet22',\n",
    "                                         role=role,\n",
    "                                         framework='mxnet',\n",
    "                                         output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy compiled model\n",
    "\n",
    "Now we will create an endpoint for the model to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_mobilenet.image = image_url\n",
    "compiled_mobilenet.name = 'deploy-pretrained-mobilenet-mxnet-ssd-test1'\n",
    "object_detector = compiled_mobilenet.deploy(initial_instance_count = 1,\n",
    "                                            instance_type = 'ml.c5.xlarge',\n",
    "                                            #endpoint_name = 'deploy-pretrained-mobilenet-mxnetml-c5',\n",
    "                                            #update_endpoint = True\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### Prepare input - Image pre-processing\n",
    "First convert image to byte array, then invoke entry point convert byte array back to PIL.Image readable file, after that, resize to required input size and convert to ndarray for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "file_name = \"test.jpg\"\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with endpoint\n",
    "\n",
    "With our Endpoint deployed successfully, we can now send inference requests to it. We'll use one image as an example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "object_detector.content_type = 'image/jpeg'\n",
    "response = object_detector.predict(payload)\n",
    "detections = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are in a format that is similar to the .lst format with an addition of a confidence score for each detected object. The format of the output can be represented as `[class_index, confidence_score, xmin, ymin, xmax, ymax]`. Typically, we don't consider low-confidence predictions.\n",
    "\n",
    "## Visualization\n",
    "\n",
    "We have provided additional script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "        from matplotlib.patches import Rectangle\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            plt.gca().text(xmin, ymin-2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', \n",
    "                     'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "                     'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "file_name = \"test.jpg\"\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "threshold = 0.40\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection(file_name, detections['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "Having an endpoint running will incur some costs. Therefore as a clean-up job, we should delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(object_detector.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
